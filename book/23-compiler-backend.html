<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Mac OS X version 4.9.20"/>

  <title></title>
</head>

<body>
  <section id="the-compiler-backend-byte-code-and-native-code" data-type="chapter">
    <h1>The Compiler Backend: Bytecode and Native code</h1>

    <p>Once OCaml has passed the type checking stage, it can stop
    emitting syntax and type errors and begin the process of
    compiling the well-formed modules into executable code.</p>

    <p>In this chapter, we'll cover the following topics:</p>

    <ul>
      <li>
        <p>The untyped intermediate lambda code where pattern
        matching is optimized</p>
      </li>

      <li>
        <p>The bytecode <span class="command"><em>ocamlc</em></span> compiler and <span class="command"><em>ocamlrun</em></span> interpreter</p>
      </li>

      <li>
        <p>The native code <span class="command"><em>ocamlopt</em></span> code generator, and
        debugging and profiling native code</p>
      </li>
    </ul>

    <section id="the-untyped-lambda-form" data-type="sect1">
      <h1>The Untyped Lambda Form</h1>

      <p>The first code generation phase eliminates all the static
      type information into a simpler intermediate <em>lambda
      form</em>. The lambda form discards higher-level constructs
      such as modules and objects and replaces them with simpler
      values such as records and function pointers. Pattern matches
      are also analyzed and compiled into highly optimized
      automata.<idx>lambda form code/basics of</idx><idx id="CPuntype">compilation process/untyped lambda form</idx></p>

      <p>The lambda form is the key stage that discards the OCaml
      type information and maps the source code to the runtime
      memory model described in <a href="20-runtime-memory-layout.html#memory-representation-of-values" data-type="xref">Memory Representation Of Values</a>. This
      stage also performs some optimizations, most notably
      converting pattern-match statements into more optimized but
      low-level statements.</p>

      <section id="pattern-matching-optimization" data-type="sect2">
        <h2>Pattern Matching Optimization</h2>

        <p>The compiler dumps the lambda form in an s-expression
        syntax if you add the <span class="keep-together"><code>-dlambda</code></span> directive to
        the command line. Let's use this to learn more about how
        the OCaml pattern-matching engine works by building three
        different pattern matches and comparing their lambda
        forms.<idx>pattern matching/optimization in lambda form code</idx><idx>lambda form code/pattern matching optimization</idx></p>

        <p>Let's start by creating a straightforward exhaustive
        pattern match using four normal variants:</p>
        <link rel="import" href="code/back-end/pattern_monomorphic_large.ml"/>

        <p>The lambda output for this code looks like this:</p>
        <link rel="import" href="code/back-end/lambda_for_pattern_monomorphic_large.sh"/>

        <p>It's not important to understand every detail of this
        internal form, and it is explicitly undocumented since it
        can change across compiler revisions. Despite these
        caveats, some interesting points emerge from reading
        it:</p>

        <ul>
          <li>
            <p>There are no mention of modules or types any more.
            Global values are created via <code>setglobal</code>,
            and OCaml values are constructed by
            <code>makeblock</code>. The blocks are the runtime
            values you should remember from <a href="20-runtime-memory-layout.html#memory-representation-of-values" data-type="xref">Memory Representation Of
            Values</a>.</p>
          </li>

          <li>
            <p>The pattern match has turned into a switch case that
            jumps to the right case depending on the header tag of
            <code>v</code>. Recall that variants without parameters
            are stored in memory as integers in the order which
            they appear. The pattern-matching engine knows this and
            has transformed the pattern into an efficient jump
            table.</p>
          </li>

          <li>
            <p>Values are addressed by a unique name that
            distinguishes shadowed values by appending a number
            (e.g., <code>v/1014</code>). The type safety checks in
            the earlier phase ensure that these low-level accesses
            never violate runtime memory safety, so this layer
            doesn't do any dynamic checks. Unwise use of unsafe
            features such as the <code>Obj.magic</code> module can
            still easily induce crashes at this level.</p>
          </li>
        </ul>

        <p>The compiler computes a jump table in order to handle
        all four cases. If we drop the number of variants to just
        two, then there's no need for the complexity of computing
        this table:</p>
        <link rel="import" href="code/back-end/pattern_monomorphic_small.ml"/>

        <p>The lambda output for this code is now quite
        different:</p>
        <link rel="import" href="code/back-end/lambda_for_pattern_monomorphic_small.sh"/>

        <p>The compiler emits simpler conditional jumps rather than
        setting up a jump table, since it statically determines
        that the range of possible variants is small enough.
        Finally, let's look at the same code, but with polymorphic
        variants instead of normal variants:</p>
        <link rel="import" href="code/back-end/pattern_polymorphic.ml"/>

        <p>The lambda form for this also shows up the runtime
        representation of polymorphic variants:</p>
        <link rel="import" href="code/back-end/lambda_for_pattern_polymorphic.sh"/>

        <p>We mentioned in <a href="06-variants.html#variants" data-type="xref">Variants</a> that pattern matching over
        polymorphic variants is slightly less efficient, and it
        should be clearer why this is the case now. Polymorphic
        variants have a runtime value that's calculated by hashing
        the variant name, and so the compiler can't use a jump
        table as it does for normal variants. Instead, it creates a
        decision tree that compares the hash values against the
        input variable in as few comparisons as possible.
        <idx>pattern matching/fundamental algorithms in</idx></p>

        <div data-type="note">
          <h1>Learning More About Pattern Matching Compilation</h1>

          <p>Pattern matching is an important part of OCaml
          programming. You'll often encounter deeply nested pattern
          matches over complex data structures in real code. A good
          paper that describes the fundamental algorithms
          implemented in OCaml is <a href="http://dl.acm.org/citation.cfm?id=507641">"Optimizing
          pattern matching"</a> by Fabrice Le Fessant and Luc
          Maranget.</p>

          <p>The paper describes the backtracking algorithm used in
          classical pattern matching compilation, and also several
          OCaml-specific optimizations, such as the use of
          exhaustiveness information and control flow optimizations
          via static exceptions.</p>

          <p>It's not essential that you understand all of this
          just to use pattern matching, of course, but it'll give
          you insight as to why pattern matching is such a
          lightweight language construct to use in OCaml code.</p>
        </div>
      </section>

      <section id="benchmarking-pattern-matching" data-type="sect2">
        <h2>Benchmarking Pattern Matching</h2>

        <p>Let's benchmark these three pattern-matching techniques
        to quantify their runtime costs more accurately. The
        <code>Core_bench</code> module runs the tests thousands of
        times and also calculates statistical variance of the
        results. You'll need to <code>opam install
        core_bench</code> to get the library:<idx>pattern matching/benchmarking of</idx><idx>lambda form code/pattern matching benchmarking</idx></p>
        <link rel="import" href="code/back-end/bench_patterns/bench_patterns.ml"/>

        <p>Building and executing this example will run for around
        30 seconds by default, and you'll see the results
        summarized in a neat table:</p>
        <link rel="import" href="code/back-end/bench_patterns/jbuild"/>
        <link rel="import" href="code/back-end/bench_patterns/run_bench_patterns.sh"/>

        <p>These results confirm the performance hypothesis that we
        obtained earlier by inspecting the lambda code. The
        shortest running time comes from the small conditional
        pattern match, and polymorphic variant pattern matching is
        the slowest. There isn't a hugely significant difference in
        these examples, but you can use the same techniques to peer
        into the innards of your own source code and narrow down
        any performance hotspots.</p>

        <p>The lambda form is primarily a stepping stone to the
        bytecode executable format that we'll cover next. It's
        often easier to look at the textual output from this stage
        than to wade through the native assembly code from compiled
        executables.<a data-type="indexterm" data-startref="CPuntype">&nbsp;</a></p>
      </section>
    </section>

    <section id="generating-portable-bytecode" data-type="sect1">
      <h1>Generating Portable Bytecode</h1>

      <p>After the lambda form has been generated, we are very
      close to having executable code. The OCaml toolchain branches
      into two separate compilers at this point. We'll describe the
      bytecode compiler first, which consists of two pieces:
      <idx>OCaml toolchain/ocamlrun</idx> <idx>OCaml toolchain/ocamlc</idx> <idx>bytecode compiler/tools used</idx>
      <idx id="CPportbyte">compilation process/portable bytecode</idx></p>

      <dl>
        <dt><span class="command"><em>ocamlc</em></span></dt>

        <dd>
          <p>Compiles files into a bytecode that is a close mapping
          to the lambda form</p>
        </dd>

        <dt><span class="command"><em>ocamlrun</em></span></dt>

        <dd>
          <p>A portable interpreter that executes the bytecode</p>
        </dd>
      </dl>

      <p>The big advantage of using bytecode is simplicity,
      portability, and compilation speed. The mapping from the
      lambda form to bytecode is straightforward, and this results
      in predictable (but slow) execution speed.</p>

      <p>The bytecode interpreter implements a stack-based virtual
      machine. The OCaml stack and an associated accumulator store
      values that consist of:<idx>bytecode compiler/values stored by</idx><idx>code offset values</idx><idx>block values</idx><idx>long values</idx><idx>values/stored by bytecode compiler</idx></p>

      <dl>
        <dt>long</dt>

        <dd>
          <p>Values that correspond to an OCaml <code>int</code>
          type</p>
        </dd>

        <dt>block</dt>

        <dd>
          <p>Values that contain the block header and a memory
          address with the data fields that contain further OCaml
          values indexed by an integer</p>
        </dd>

        <dt>code offset</dt>

        <dd>
          <p>Values that are relative to the starting code
          address</p>
        </dd>
      </dl>

      <p>The interpreter virtual machine only has seven registers
      in total: the program counter, stack pointer, accumulator,
      exception and argument pointers, and environment and global
      data. You can display the bytecode instructions in textual
      form via <code>-dinstr</code>. Try this on one of our earlier
      pattern-matching examples:</p>
      <link rel="import" href="code/back-end/instr_for_pattern_monomorphic_small.sh"/>

      <p>The preceding bytecode has been simplified from the lambda
      form into a set of simple instructions that are executed
      serially by the interpreter.</p>

      <p>There are around 140 instructions in total, but most are
      just minor variants of commonly encountered operations (e.g.,
      function application at a specific arity). You can find full
      details <a href="http://cadmium.x9c.fr/distrib/caml-instructions.pdf">online</a>.
      <idx>bytecode compiler/instruction set for</idx></p>

      <div data-type="note">
        <h1>Where Did the Bytecode Instruction Set Come From?</h1>

        <p>The bytecode interpreter is much slower than compiled
        native code, but is still remarkably performant for an
        interpreter without a JIT compiler. Its efficiency can be
        traced back to Xavier Leroy's ground-breaking work in 1990,
        <a href="http://hal.inria.fr/docs/00/07/00/49/PS/RT-0117.ps">"The
        ZINC experiment: An Economical Implementation of the ML
        Language".</a></p>

        <p>This paper laid the theoretical basis for the
        implementation of an instruction set for a strictly
        evaluated functional language such as OCaml. The bytecode
        interpreter in modern OCaml is still based on the ZINC
        model. The native code compiler uses a different model
        since it uses CPU registers for function calls instead of
        always passing arguments on the stack, as the bytecode
        interpreter does.</p>

        <p>Understanding the reasoning behind the different
        implementations of the bytecode interpreter and the native
        compiler is a very useful exercise for any budding language
        hacker.</p>
      </div>

      <section id="compiling-and-linking-bytecode" data-type="sect2">
        <h2>Compiling and Linking Bytecode</h2>

        <p>The <span class="command"><em>ocamlc</em></span> command
        compiles individual <code>ml</code> files into bytecode
        files that have a <code>cmo</code> extension. The compiled
        bytecode files are matched with the associated
        <code>cmi</code> interface, which contains the type
        signature exported to other compilation units.
        <idx>bytecode compiler/compiling and linking code</idx></p>

        <p>A typical OCaml library consists of multiple source
        files, and hence multiple <code>cmo</code> files that all
        need to be passed as command-line arguments to use the
        library from other code. The compiler can combine these
        multiple files into a more convenient single archive file
        by using the <code>-a</code> flag. Bytecode archives are
        denoted by the <code>cma</code> extension.</p>

        <p>The individual objects in the library are linked as
        regular <code>cmo</code> files in the order specified when
        the library file was built. If an object file within the
        library isn't referenced elsewhere in the program, then it
        isn't included in the final binary unless the
        <code>-linkall</code> flag forces its inclusion. This
        behavior is analogous to how C handles object files and
        archives (<code>.o</code> and <code>.a</code>,
        respectively).</p>

        <p>The bytecode files are then linked together with the
        OCaml standard library to produce an executable program.
        The order in which <code>.cmo</code> arguments are
        presented on the command line defines the order in which
        compilation units are initialized at runtime. Remember that
        OCaml has no single <code>main</code> function like C, so
        this link order is more important than in C programs.</p>
      </section>

      <section id="executing-bytecode" data-type="sect2">
        <h2>Executing Bytecode</h2>

        <p>The bytecode runtime comprises three parts: the bytecode
        interpreter, GC, and a set of C functions that implement
        the primitive operations. The bytecode contains
        instructions to call these C functions when required.</p>

        <p>The OCaml linker produces bytecode that targets the
        standard OCaml runtime by default, and so needs to know
        about any C functions that are referenced from other
        libraries that aren't loaded by default.</p>

        <p>Information about these extra libraries can be specified
        while linking a bytecode archive:</p>
        <link rel="import" href="code/back-end-embed/link_dllib.rawsh"/>

        <p>The <code>dllib</code> flag embeds the arguments in the
        archive file. Any subsequent packages linking this archive
        will also include the extra C linking directive. This in
        turn lets the interpreter dynamically load the external
        library symbols when it executes the bytecode.</p>

        <p>You can also generate a complete standalone executable
        that bundles the <span class="command"><em>ocamlrun</em></span> interpreter with the
        bytecode in a single binary. This is known as a <em>custom
        runtime</em> mode and is built as follows: <idx>custom runtime mode</idx></p>
        <link rel="import" href="code/back-end-embed/link_custom.rawsh"/>

        <p>OCamlbuild takes care of many of these details with its
        built-in rules. The <code>%.byte</code> rule that you've
        been using throughout the book builds a bytecode
        executable, and adding the <code>custom</code> tag will
        bundle the interpreter with it, too. <idx>%.byte rule</idx></p>

        <p>The custom mode is the most similar mode to native code
        compilation, as both generate standalone executables. There
        are quite a few other options available for compiling
        bytecode (notably with shared libraries or building custom
        runtimes). Full details can be found in the <a href="http://caml.inria.fr/pub/docs/manual-ocaml/manual022.html">
        OCaml</a>.</p>
      </section>

      <section id="embedding-ocaml-bytecode-in-c" data-type="sect2">
        <h2>Embedding OCaml Bytecode in C</h2>

        <p>A consequence of using the bytecode compiler is that the
        final link phase must be performed by <span class="command"><em>ocamlc</em></span>. However, you might
        sometimes want to embed your OCaml code inside an existing
        C application. OCaml also supports this mode of operation
        via the <span class="keep-together"><code>-output-obj</code></span>
        directive.<idx>C object files</idx></p>

        <p>This mode causes <span class="command"><em>ocamlc</em></span> to output an object file
        containing the bytecode for the OCaml part of the program,
        as well as a <code>caml_startup</code> function. All of the
        OCaml modules are linked into this object file as bytecode,
        just as they would be for an executable.</p>

        <p>This object file can then be linked with C code using
        the standard C compiler, needing only the bytecode runtime
        library (which is installed as <code>libcamlrun.a</code>).
        Creating an executable just requires you to link the
        runtime library with the bytecode object file. Here's an
        example to show how it all fits together.</p>

        <p>Create two OCaml source files that contain a single
        print line:</p>
        <link rel="import" href="code/back-end-embed/embed_me1.ml"/>
        <link rel="import" href="code/back-end-embed/embed_me2.ml"/>

        <p>Next, create a C file to be your main entry point:</p>
        <link rel="import" href="code/back-end-embed/main.c"/>

        <p>Now compile the OCaml files into a standalone object
        file:</p>
        <link rel="import" href="code/back-end-embed/build_embed.sh" part="o"/>

        <p>After this point, you no longer need the OCaml compiler,
        as <code>embed_out.o</code> has all of the OCaml code
        compiled and linked into a single object file. Compile an
        output binary using <span class="command"><em>gcc</em></span> to test this out:</p>
        <link rel="import" href="code/back-end-embed/build_embed_binary.rawsh"/>

        <p>You can inspect the commands that <span class="command"><em>ocamlc</em></span> is invoking by adding
        <code>-verbose</code> to the command line to help figure
        out the GCC command line if you get stuck. You can even
        obtain the C source code to the <code>-output-obj</code>
        result by specifying a <code>.c</code> output file
        extension instead of the <code>.o</code> we used
        earlier:</p>
        <link rel="import" href="code/back-end-embed/build_embed.sh" part="c"/>

        <p>Embedding OCaml code like this lets you write OCaml that
        interfaces with any environment that works with a C
        compiler. You can even cross back from the C code into
        OCaml by using the <code>Callback</code> module to register
        named entry points in the OCaml code. This is explained in
        detail in the <a href="http://caml.inria.fr/pub/docs/manual-ocaml/manual033.html#toc149">
        interfacing with C</a> section of the OCaml manual.
        <a data-type="indexterm" data-startref="CPportbyte">&nbsp;</a></p>
      </section>
    </section>

    <section id="compiling-fast-native-code" data-type="sect1">
      <h1>Compiling Fast Native Code</h1>

      <p>The native code compiler is ultimately the tool that most
      production OCaml code goes through. It compiles the lambda form
      into fast native code executables, with cross-module inlining
      and additional optimization passes that the bytecode interpreter
      doesn't perform. Care is taken to ensure compatibility with the
      bytecode runtime, so the same code should run identically when
      compiled with either toolchain.

	<idx>cmi files</idx>
	<idx>files/cmi files</idx>
	<idx>cmx files</idx>
	<idx>files/cmx files</idx>
	<idx>o files</idx>
	<idx>files/o files</idx>
	<idx>OCaml toolchain/ocamlopt</idx>
	<idx>native-code compiler/benefits of</idx>
	<idx id="CPfast">compilation process/fast native code</idx></p>

      <p>The <span class="command"><em>ocamlopt</em></span> command
      is the frontend to the native code compiler and has a very
      similar interface to <span class="command"><em>ocamlc</em></span>. It also accepts
      <code>ml</code> and <code>mli</code> files, but compiles them
      to:</p>

      <ul>
        <li>
          <p>A <code>.o</code> file containing native object
          code</p>
        </li>

        <li>
          <p>A <code>.cmx</code> file containing extra information
          for linking and cross-module optimization</p>
        </li>

        <li>
          <p>A <code>.cmi</code> compiled interface file that is
          the same as the bytecode compiler</p>
        </li>
      </ul>

      <p>When the compiler links modules together into an
      executable, it uses the contents of the <code>cmx</code>
      files to perform cross-module inlining across compilation
      units. This can be a significant speedup for standard library
      functions that are frequently used outside of their
      module.</p>

      <p>Collections of <code>.cmx</code> and <code>.o</code> files
      can also be be linked into a <code>.cmxa</code> archive by
      passing the <code>-a</code> flag to the compiler. However,
      unlike the bytecode version, you must keep the individual
      <code>cmx</code> files in the compiler search path so that
      they are available for cross-module inlining. If you don't do
      this, the compilation will still succeed, but you will have
      missed out on an important optimization and have slower
      binaries.</p>

      <section id="inspecting-assembly-output" data-type="sect2">
        <h2>Inspecting Assembly Output</h2>

        <p>The native code compiler generates assembly language
        that is then passed to the system assembler for compiling
        into object files. You can get <span class="command"><em>ocamlopt</em></span> to output the assembly
        by passing the <code>-S</code> flag to the compiler command
        line.<idx>native-code compiler/inspecting assembly output</idx></p>

        <p>The assembly code is highly architecture-specific, so
        the following discussion assumes an Intel or AMD 64-bit
        platform. We've generated the example code using
        <code>-inline 20</code> and <code>-nodynlink</code> since
        it's best to generate assembly code with the full
        optimizations that the compiler supports. Even though these
        optimizations make the code a bit harder to read, it will
        give you a more accurate picture of what executes on the
        CPU. Don't forget that you can use the lambda code from
        earlier to get a slightly higher-level picture of the code
        if you get lost in the more verbose assembly.</p>

        <section id="the-impact-of-polymorphic-comparison" data-type="sect3">
          <h3>The impact of polymorphic comparison</h3>

          <p>We warned you in <a href="13-maps-and-hashtables.html#maps-and-hash-tables" data-type="xref">Maps And Hash Tables</a> that using
          polymorphic comparison is both convenient and perilous.
          Let's look at precisely what the difference is at the
          assembly language level now.<idx>polymorphic comparisons</idx></p>

          <p>First let's create a comparison function where we've
          explicitly annotated the types, so the compiler knows
          that only integers are being compared:</p>
          <link rel="import" href="code/back-end/compare_mono.ml"/>

          <p>Now compile this into assembly and read the resulting
          <code>compare_mono.S</code> file. This file extension may
          be lowercase on some platforms such as Linux:</p>
          <link rel="import" href="code/back-end/asm_from_compare_mono.sh"/>

          <p>If you've never seen assembly language before, then
          the contents may be rather scary. While you'll need to
          learn x86 assembly to fully understand it, we'll try to
          give you some basic instructions to spot patterns in this
          section. The excerpt of the implementation of the
          <code>cmp</code> function can be found below:</p>
          <link rel="import" href="code/back-end/cmp.S"/>

          <p>The <code>_camlCompare_mono__cmp_1008</code> is an
          assembly label that has been computed from the module
          name (<code>Compare_mono</code>) and the function name
          (<code>cmp_1008</code>). The numeric suffix for the
          function name comes straight from the lambda form (which
          you can inspect using <code>-dlambda</code>, but in this
          case isn't necessary).</p>

          <p>The arguments to <code>cmp</code> are passed in the
          <code>%rbx</code> and <code>%rax</code> registers, and
          compared using the <code>jle</code> "jump if less than or
          equal" instruction. This requires both the arguments to
          be immediate integers to work. Now let's see what happens
          if our OCaml code omits the type annotations and is a
          polymorphic comparison instead:</p>
          <link rel="import" href="code/back-end/compare_poly.ml"/>

          <p>Compiling this code with <code>-S</code> results in a
          significantly more complex assembly output for the same
          function:</p>
          <link rel="import" href="code/back-end/compare_poly_asm.S"/>

          <p>The <code>.cfi</code> directives are assembler hints
          that contain Call Frame Information that lets the
          debugger provide more sensible backtraces, and they have
          no effect on runtime performance. Notice that the rest of
          the implementation is no longer a simple register
          comparison. Instead, the arguments are pushed on the
          stack (the <code>%rsp</code> register), and a C function
          call is invoked by placing a pointer to
          <code>caml_greaterthan</code> in <code>%rax</code> and
          jumping to <code>caml_c_call</code>. <idx>backtraces</idx></p>

          <p>OCaml on x86_64 architectures caches the location of
          the minor heap in the <code>%r15</code> register since
          it's so frequently referenced in OCaml functions. The
          minor heap pointer can also be changed by the C code
          that's being called (e.g., when it allocates OCaml
          values), and so <code>%r15</code> is restored after
          returning from the <code>caml_greaterthan</code> call.
          Finally, the return value of the comparison is popped
          from the stack and returned.</p>
        </section>

        <section id="benchmarking-polymorphic-comparison" data-type="sect3">
          <h3>Benchmarking polymorphic comparison</h3>

          <p>You don't have to fully understand the intricacies of
          assembly language to see that this polymorphic comparison
          is much heavier than the simple monomorphic integer
          comparison from earlier. Let's confirm this hypothesis
          again by writing a quick <code>Core_bench</code> test
          with both functions:</p>
          <link rel="import" href="code/back-end/bench_poly_and_mono/bench_poly_and_mono.ml"/>

          <p>Running this shows quite a significant runtime
          difference between the two:</p>
          <link rel="import" href="code/back-end/bench_poly_and_mono/jbuild"/>
          <link rel="import" href="code/back-end/bench_poly_and_mono/run_bench_poly_and_mono.sh"/>

          <p>We see that the polymorphic comparison is close to 20
          times slower! These results shouldn't be taken too
          seriously, as this is a very narrow test that, like all
          such microbenchmarks, isn't representative of more
          complex codebases. However, if you're building numerical
          code that runs many iterations in a tight inner loop,
          it's worth manually peering at the produced assembly code
          to see if you can hand-optimize it.</p>
        </section>
      </section>

      <section id="debugging-native-code-binaries" data-type="sect2">
        <h2>Debugging Native Code Binaries</h2>

        <p>The native code compiler builds executables that can be
        debugged using conventional system debuggers such as GNU
        <span class="command"><em>gdb</em></span>. You need to
        compile your libraries with the <code>-g</code> option to
        add the debug information to the output, just as you need
        to with C compilers. <idx>debugging/native code binaries</idx> <idx>native-code compiler/debugging binaries</idx></p>

        <p>Extra debugging information is inserted into the output
        assembly when the library is compiled in debug mode. These
        include the CFI stubs you will have noticed in the
        profiling output earlier (<code>.cfi_start_proc</code> and
        <code>.cfi_end_proc</code> to delimit an OCaml function
        call, for example).</p>

        <section id="understanding-name-mangling" data-type="sect3">
          <h3>Understanding name mangling</h3>

          <p>So how do you refer to OCaml functions in an
          interactive debugger like <span class="command"><em>gdb</em></span>? The first thing you need
          to know is how OCaml function names compile down to
          symbol names in the compiled object files, a procedure
          generally called <em>name mangling</em>.<idx>gdb debugger</idx><idx>debugging/interactive debuggers</idx><idx>functions/name mangling of</idx><idx>name mangling</idx></p>

          <p>Each OCaml source file is compiled into a native
          object file that must export a unique set of symbols to
          comply with the C binary interface. This means that any
          OCaml values that may be used by another compilation unit
          need to be mapped onto a symbol name. This mapping has to
          account for OCaml language features such as nested
          modules, anonymous functions, and variable names that
          shadow one another.</p>

          <p>The conversion follows some straightforward rules for
          named variables and functions:</p>

          <ul>
            <li>
              <p>The symbol is prefixed by <code>caml</code> and
              the local module name, with dots replaced by
              underscores.</p>
            </li>

            <li>
              <p>This is followed by a double <code>__</code>
              suffix and the variable name.</p>
            </li>

            <li>
              <p>The variable name is also suffixed by a
              <code>_</code> and a number. This is the result of
              the lambda compilation, which replaces each variable
              name with a unique value within the module. You can
              determine this number by examining the
              <code>-dlambda</code> output from <span class="command"><em>ocamlopt</em></span>.</p>
            </li>
          </ul>

          <p>Anonymous functions are hard to predict without
          inspecting intermediate compiler output. If you need to
          debug them, it's usually easier to modify the source code
          to let-bind the anonymous function to a variable
          name.</p>
        </section>

        <section id="interactive-breakpoints-with-the-gnu-debugger" data-type="sect3">
          <h3>Interactive breakpoints with the GNU debugger</h3>

          <p>Let's see name mangling in action with some
          interactive debugging using GNU <span class="command"><em>gdb</em></span>. <idx>GNU debugger</idx></p>

          <div data-type="caution">
            <h1>Beware gdb on Mac OS X</h1>

            <p>The examples here assume that you are running
            <span class="command"><em>gdb</em></span> on either
            Linux or FreeBSD. Mac OS X 10.8 does have <span class="command"><em>gdb</em></span> installed, but it's a
            rather quirky experience that doesn't reliably
            interpret the debugging information contained in the
            native binaries. This can result in function names
            showing up as raw symbols such as <code>.L101</code>
            instead of their more human-readable form.</p>

            <p>For OCaml 4.1, we'd recommend you do native code
            debugging on an alternate platform such as Linux, or
            manually look at the assembly code output to map the
            symbol names onto their precise OCaml functions.</p>

            <p>MacOS 10.9 removes <span class="command"><em>gdb</em></span> entirely and uses the
            lldb debugger from the LLVM project by default. Many of
            the guidelines here still apply since the debug
            information embedded in the binary output can be
            interpreted by lldb (or any other DWARF-aware
            debugger), but the command-line interfaces to lldb is
            different from <span class="command"><em>gdb</em></span>. Refer to the lldb manual
            for more information.</p>
          </div>

          <p>Let's write a mutually recursive function that selects
          alternating values from a list. This isn't
          tail-recursive, so our stack size will grow as we
          single-step through the execution:</p>
          <link rel="import" href="code/back-end/alternate_list/alternate_list.ml"/>

          <p>Compile and run this with debugging symbols. You
          should see the following output:</p>
          <link rel="import" href="code/back-end/alternate_list/jbuild"/>
          <link rel="import" href="code/back-end/alternate_list/run_alternate_list.sh"/>

          <p>Now we can run this interactively within <span class="command"><em>gdb</em></span>:</p>
          <link rel="import" href="code/back-end/gdb_alternate0.rawsh"/>

          <p>The <span class="command"><em>gdb</em></span> prompt
          lets you enter debug directives. Let's set the program to
          break just before the first call to
          <code>take</code>:</p>
          <link rel="import" href="code/back-end/gdb_alternate1.rawsh"/>

          <p>We used the C symbol name by following the name
          mangling rules defined earlier. A convenient way to
          figure out the full name is by tab completion. Just type
          in a portion of the name and press the &lt;tab&gt; key to
          see a list of possible completions.</p>

          <p>Once you've set the breakpoint, start the program
          executing:</p>
          <link rel="import" href="code/back-end/gdb_alternate2.rawsh"/>

          <p>The binary has run until the first take invocation and
          stopped, waiting for further instructions. GDB has lots
          of features, so let's continue the program and check the
          stacktrace after a couple of recursions:</p>
          <link rel="import" href="code/back-end/gdb_alternate3.rawsh"/>

          <p>The <code>cont</code> command resumes execution after
          a breakpoint has paused it, <code>bt</code> displays a
          stack backtrace, and <code>clear</code> deletes the
          breakpoint so the application can execute until
          completion. GDB has a host of other features we won't
          cover here, but you can view more guidelines via Mark
          Shinwell's talk on <a href="http://www.youtube.com/watch?v=NF2WpWnB-nk%3C">"Real-world
          debugging in OCaml."</a></p>

          <p>One very useful feature of OCaml native code is that C
          and OCaml share the same stack. This means that GDB
          backtraces can give you a combined view of what's going
          on in your program <em>and</em> runtime library. This
          includes any calls to C libraries or even callbacks into
          OCaml from the C layer if you're in an environment which
          embeds the OCaml runtime as a library.</p>
        </section>
      </section>

      <section id="profiling-native-code" data-type="sect2">
        <h2>Profiling Native Code</h2>

        <p>The recording and analysis of where your application
        spends its execution time is known as <em>performance
        profiling</em>. OCaml native code binaries can be profiled
        just like any other C binary, by using the name mangling
        described earlier to map between OCaml variable names and
        the profiler output. <idx>profiling</idx> <idx>performance profiling</idx>
        <idx>native-code compiler/performance profiling</idx></p>

        <p>Most profiling tools benefit from having some
        instrumentation included in the binary. OCaml supports two
        such tools:</p>

        <ul>
          <li>
            <p>GNU <span class="command"><em>gprof</em></span>, to
            measure execution time and call graphs</p>
          </li>

          <li>
            <p>The <a href="https://perf.wiki.kernel.org/">Perf</a>
            profiling framework in modern versions of Linux</p>
          </li>
        </ul>

        <p>Note that many other tools that operate on native
        binaries, such as Valgrind, will work just fine with OCaml
        as long as the program is linked with the <code>-g</code>
        flag to embed debugging symbols.</p>

        <section id="gprof" data-type="sect3">
          <h3>Gprof</h3>

          <p><span class="command"><em>gprof</em></span> produces
          an execution profile of an OCaml program by recording a
          call graph of which functions call one another, and
          recording the time these calls take during the program
          execution.<idx>gprof code profiler</idx></p>

          <p>Getting precise information out of <span class="command"><em>gprof</em></span> requires passing the
          <code>-p</code> flag to the native code compiler when
          compiling <em>and</em> linking the binary. This generates
          extra code that records profile information to a file
          called <code>gmon.out</code> when the program is
          executed. This profile information can then be examined
          using <span class="command"><em>gprof</em></span>.</p>
        </section>

        <section id="perf" data-type="sect3">
          <h3>Perf</h3>

          <p>Perf is a more modern alternative to <span class="command"><em>gprof</em></span> that doesn't require you
          to instrument the binary. Instead, it uses hardware
          counters and debug information within the binary to
          record information accurately.</p>

          <p>Run Perf on a compiled binary to record information
          first. We'll use our write barrier benchmark from
          earlier, which measures memory allocation versus in-place
          modification:</p>
          <link rel="import" href="code/back-end/perf_record.rawsh"/>

          <p>When this completes, you can interactively explore the
          results:</p>
          <link rel="import" href="code/back-end/perf_report.rawsh"/>

          <p>This trace broadly reflects the results of the
          benchmark itself. The mutable benchmark consists of the
          combination of the call to <code>test_mutable</code> and
          the <code>caml_modify</code> write barrier function in
          the runtime. This adds up to slightly over half the
          execution time of the application.</p>

          <p>Perf has a growing collection of other commands that
          let you archive these runs and compare them against each
          other. You can read more on the <a href="http://perf.wiki.kernel.org">home page</a>.
          <idx>frame pointers</idx></p>

          <aside data-type="sidebar">
            <h5>Using the Frame Pointer to Get More Accurate
            Traces</h5>

            <p>Although Perf doesn't require adding in explicit
            probes to the binary, it does need to understand how to
            unwind function calls so that the kernel can accurately
            record the function backtrace for every event.</p>

            <p>OCaml stack frames are too complex for Perf to
            understand directly, and so it needs the compiler to
            fall back to using the same conventions as C for
            function calls. On 64-bit Intel systems, this means
            that a special register known as the <em>frame
            pointer</em> is used to record function call
            history.</p>

            <p>Using the frame pointer in this fashion means a
            slowdown (typically around 3-5%) since it's no longer
            available for general-purpose use. OCaml 4.1 thus makes
            the frame pointer an optional feature that can be used
            to improve the resolution of Perf traces.</p>

            <p>OPAM provides a compiler switch that compiles OCaml
            with the frame pointer activated:</p>
            <link rel="import" href="code/back-end/opam_switch.rawsh"/>

            <p>Using the frame pointer changes the OCaml calling
            convention, but OPAM takes care of recompiling all your
            libraries with the new interface. You can read more
            about this on the OCamlPro <a href="http://www.ocamlpro.com/blog/2012/08/08/profile-native-code.html">
            blog</a>.</p>
          </aside>
        </section>
      </section>

      <section id="embedding-native-code-in-c" data-type="sect2">
        <h2>Embedding Native Code in C</h2>

        <p>The native code compiler normally links a complete
        executable, but can also output a standalone native object
        file just as the bytecode compiler can. This object file
        has no further dependencies on OCaml except for the runtime
        library.<idx>libasmrun.a library</idx> <idx>native-code compiler/embedding code in C</idx></p>

        <p>The native code runtime is a different library from the
        bytecode one, and is installed as <code>libasmrun.a</code>
        in the OCaml standard library directory.</p>

        <p>Try this custom linking by using the same source files
        from the bytecode embedding example earlier in this
        chapter:</p>
        <link rel="import" href="code/back-end-embed/build_embed_native.rawsh"/>

        <p>The <code>embed_native.o</code> is a standalone object
        file that has no further references to OCaml code beyond
        the runtime library, just as with the bytecode runtime. Do
        remember that the link order of the libraries is
        significant in modern GNU toolchains (especially as used in
        Ubuntu 11.10 and later) that resolve symbols from left to
        right in a single pass.<idx>debugging/activating debug runtime</idx></p>

        <div data-type="tip">
          <h1>Activating the Debug Runtime</h1>

          <p>Despite your best efforts, it is easy to introduce a
          bug into some components, such as C bindings, that causes
          heap invariants to be violated. OCaml includes a
          <code>libasmrund.a</code> variant of the runtime library
          which is compiled with extra debugging checks that
          perform extra memory integrity checks during every
          garbage collection cycle. Running these extra checks will
          abort the program nearer the point of corruption and help
          isolate the bug in the C code.</p>

          <p>To use the debug library, just link your program with
          the <code>-runtime-variant d</code> flag:</p>
        </div>
        <link rel="import" href="code/back-end-embed/run_debug_hello.sh"/>

        <p>If you get an error that <code>libasmrund.a</code> is
        not found, it's probably because you're using OCaml 4.00
        and not 4.01. It's only installed by default in the very
        latest version, which you should be using via the
        <code>4.01.0</code> OPAM switch. <a data-type="indexterm" data-startref="CPfast">&nbsp;</a></p>
      </section>
    </section>

    <section id="summarizing-the-file-extensions" data-type="sect1">
      <h1>Summarizing the File Extensions</h1>

      <p>We've seen how the compiler uses intermediate files to
      store various stages of the compilation toolchain. Here's a
      cheat sheet of all them in one place. <idx>files/chart of file extensions</idx> <idx>compilation process/file extensions</idx></p>

      <p><a href="23-compiler-backend.html#Table2301" data-type="xref">Table2301</a> shows the intermediate files generated
      by <span class="command"><em>ocamlc</em></span>.</p>

      <table id="Table2301">
        <caption>
          Intermediate files generated by the OCaml compiler
          toolchain
        </caption>

        <thead>
          <tr>
            <th>Extension</th>

            <th>Purpose</th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td><code>.ml</code></td>

            <td>Source files for compilation unit module
            implementations.</td>
          </tr>

          <tr>
            <td><code>.mli</code></td>

            <td>Source files for compilation unit module
            interfaces. If missing, generated from the
            <code>.ml</code> file.</td>
          </tr>

          <tr>
            <td><code>.cmi</code></td>

            <td>Compiled module interface from a corresponding
            <code>.mli</code> source file.</td>
          </tr>

          <tr>
            <td><code>.cmo</code></td>

            <td>Compiled bytecode object file of the module
            implementation.</td>
          </tr>

          <tr>
            <td><code>.cma</code></td>

            <td>Library of bytecode object files packed into a
            single file.</td>
          </tr>

          <tr>
            <td><code>.o</code></td>

            <td>C source files are compiled into native object
            files by the system <code>cc</code>.</td>
          </tr>

          <tr>
            <td><code>.cmt</code></td>

            <td>Typed abstract syntax tree for module
            implementations.</td>
          </tr>

          <tr>
            <td><code>.cmti</code></td>

            <td>Typed abstract syntax tree for module
            interfaces.</td>
          </tr>

          <tr>
            <td><code>.annot</code></td>

            <td>Old-style annotation file for displaying
            <code>typed</code>, superseded by <code>cmt</code>
            files.</td>
          </tr>
        </tbody>
      </table>

      <p>The native code compiler generates some additional files
      (see <a href="23-compiler-backend.html#Table2302" data-type="xref">Table2302</a>).<idx>native-code compiler/files generated by</idx></p>

      <table id="Table2302">
        <caption>
          Intermediate outputs produced by the native code OCaml
          toolchain
        </caption>

        <thead>
          <tr>
            <th>Extension</th>

            <th>Purpose</th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td><code>.o</code></td>

            <td>Compiled native object file of the module
            implementation.</td>
          </tr>

          <tr>
            <td><code>.cmx</code></td>

            <td>Contains extra information for linking and
            cross-module optimization of the object file.</td>
          </tr>

          <tr>
            <td><code>.cmxa and .a</code></td>

            <td>Library of <code>cmx</code> and <code>o</code>
            units, stored in the <code>cmxa</code> and
            <code>a</code> files respectively. These files are
            always needed together.</td>
          </tr>

          <tr>
            <td><code>.S</code> <em>or</em> <code>.s</code></td>

            <td>Assembly language output if <code>-S</code> is
            specified.</td>
          </tr>
        </tbody>
      </table>
    </section>
  </section>
</body>
</html>
